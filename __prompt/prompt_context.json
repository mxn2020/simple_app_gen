{
    "process.md": "lets create a symple python app using this library.\n\n- setup memory_string\n- send project name and description to nlp and request feature list\n- add feature list to memory_string\n- send memory_string to nlp and request file and folder structure\n- add file and folder structure to memory_string\n- send memory_string to nlp and request plan for implementation\n- add plan for implementation to memory_string\n- add memory_string as context to prompt_string with attributes: instructions, context, tech_stack\n- send prompt_string to nlp and request implementation of the first file, with response structure {\"response\": str, \"file_path\": str}\n- add file_path and response to prompt_string\n- check if folder of file_path exist, if not, create folder (folders can contain multiple sub folders, create all subfolders)\n- check if file exists, if file does not exist create it and save response text inside it\n- if the file exists, create a new  file with the same name and a suffix \"_updated\", (check if that exists too and add numbers to suffix until it does not exist)\n\nLOOP BEGIN\n- send prompt_string to nlp and request implementation of the next file, with response structure {\"response\": str, \"file_path\": str}\n- add file_path and response to prompt_string\n- check if folder of file_path exist, if not, create folder (folders can contain multiple sub folders, create all subfolders)\n- check if file exists, if file does not exist create it and save response text inside it\n- if the file exists, create a new  file with the same name and a suffix \"_updated\", (check if that exists too and add numbers to suffix until it does not exist)\nLOOP END\n\nrepeat LOOP until nlp response contains \"FINISHED WITH SCRIPT\"",
    "MemoryManager.py": "import json\n\nclass MemoryManager:\n    def __init__(self):\n        self.memory = {\n            \"initial_setup\": {}, \"author_persona\": {}, \"book\": {},\n            \"recipe_chapters\": {}, \"detailed_content\": {}, \"recipe_variations\": {},\n            \"compilation\": {}, \"final_memory\": {}, \"metadata\": {}, \"project\": {}\n        }\n    \n    def update_memory(self, section, keys, value):\n        # Navigate through the keys to find the right place to update\n        current = self.memory[section]\n        for key in keys[:-1]:  # All keys except the last\n            if key not in current or not isinstance(current[key], dict):\n                current[key] = {}  # Initialize a new dictionary if the key doesn't exist\n            current = current[key]\n        current[keys[-1]] = value  # Set the value at the final key\n\n    def get_memory(self, section, keys):\n        # Retrieve value using nested keys\n        current = self.memory[section]\n        for key in keys:\n            if key not in current:\n                return None  # Key not found\n            current = current[key]\n        return current\n\n    def delete_memory(self, section, keys):\n        # Delete value using nested keys\n        current = self.memory[section]\n        for key in keys[:-1]:\n            if key not in current:\n                return  # Key not found\n            current = current[key]\n        del current[keys[-1]]\n\n    def get_all_memory(self, section):\n        # Get all memory in a section\n        return self.memory[section]\n    \n    def get_response(self):\n        # Get the response from memory.\n        return self.get_memory(\"response\", [])\n    \n    def save_response(self, response):\n        # Save the response from OpenAI to memory.\n        self.update_memory(\"response\", [], response)\n\n    def get_role(self):\n        #        self.memory_manager.update_memory(\"author_persona\", [\"persona\"], author_persona)\n        role = self.get_memory(\"author_persona\", [\"persona\"])\n        return role\n\n    def exists(self, section, keys):\n        # Check if the value exists in memory\n        return self.get_memory(section, keys) is not None\n    \n    def get_all_keys(self):\n        # Get all keys in memory\n        return list(self.memory.keys())\n\n    def save_to_file(self, filename):\n        with open(filename, 'w') as file:\n            json.dump(self.memory, file, indent=4)\n\n    def load_from_file(self, filename):\n        with open(filename, 'r') as file:\n            self.memory = json.load(file)",
    "ProjectFolderCreator.py": "import os\nimport json\nfrom datetime import datetime\nfrom maldinio_ai import ModuleMemory\n\nclass ProjectFolderCreator:\n    def __init__(self, memory: ModuleMemory):\n        self.main_key = \"project\"\n        self.key = \"files\"\n        self.sub_key = \"project_folder\"\n        self.memory = memory\n        self.root_folder = \"__temp_project\"\n        self.project_name = \"project_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        self.full_path = os.path.join(self.root_folder, self.project_name)\n        self.full_path_prompts = os.path.join(self.root_folder, self.project_name, \"prompts\")\n        self.full_path_responses = os.path.join(self.root_folder, self.project_name, \"responses\")\n        self.full_path_output = os.path.join(self.root_folder, self.project_name, \"output\")\n\n    def get_key(self):\n        return self.key\n    \n    def get_main_key(self):\n        return self.main_key\n    \n    def get_sub_key(self):\n        return self.sub_key\n\n    def execute(self):\n        self.create_project_directory()\n\n    def create_project_directory(self):\n        if not os.path.exists(self.full_path):\n            os.makedirs(self.full_path)\n            print(f\"Created project directory: {self.full_path}\")\n        else:\n            print(f\"Project directory already exists: {self.full_path}\")\n                \n        if not os.path.exists(self.full_path_prompts):\n            os.makedirs(self.full_path_prompts)\n            print(f\"Created prompts directory: {self.full_path_prompts}\")\n        else:\n            print(f\"Prompts directory already exists: {self.full_path_prompts}\")\n            \n        if not os.path.exists(self.full_path_responses):\n            os.makedirs(self.full_path_responses)\n            print(f\"Created responses directory: {self.full_path_responses}\")\n        else:\n            print(f\"Responses directory already exists: {self.full_path_responses}\")\n            \n        if not os.path.exists(self.full_path_output):\n            os.makedirs(self.full_path_output)\n            print(f\"Created output directory: {self.full_path_output}\")\n        else:\n            print(f\"Output directory already exists: {self.full_path_output}\")\n            \n                                 \n        self.memory.create([self.main_key, self.key, self.sub_key], self.full_path)\n        self.memory.create([self.main_key, self.key, \"prompt_folder\"], self.full_path_prompts)\n        self.memory.create([self.main_key, self.key, \"response_folder\"], self.full_path_responses)\n        self.memory.create([self.main_key, self.key, \"output_folder\"], self.full_path_output)\n",
    "test.py": "import os\nimport json\nfrom maldinio_ai import NLPClient, PromptContext, PromptGenerator, OpenAIKeyLoader, NLPProcessor, ModuleMemory\nfrom ProjectFolderCreator import ProjectFolderCreator\nfrom MemoryManager import MemoryManager\n\ndef parse_response(response):\n    try:\n        # Try parsing the response as is\n        return json.loads(response)\n    except json.decoder.JSONDecodeError as e:\n        # If a JSONDecodeError is encountered, try fixing the quotes\n        try:\n            corrected_response = response.replace(\"'\", '\"')\n            return json.loads(corrected_response)\n        except Exception as e:\n            # Log the error, raise an exception, or handle it as needed\n            print(f\"Failed to parse the response even after quote correction: {e}\")\n            raise\n\n# Simulated NLP client using the PromptContext and PromptGenerator\nclass MockNLPClient:\n    def process(self, prompt):\n        print(f\"Sending prompt to NLP model: {prompt}\")\n        # This is where you'd send the prompt to the actual NLP model. For now, it returns mocked responses.\n        if \"feature list\" in prompt:\n            return json.dumps([\"Login system\", \"Data visualization\", \"API integration\"])\n        elif \"file and folder structure\" in prompt:\n            return json.dumps({\n                \"folders\": [\"src\", \"docs\", \"tests\"],\n                \"files\": [\"src/app.py\", \"src/utils.py\", \"README.md\"]\n            })\n        elif \"implementation plan\" in prompt:\n            return \"Setup project structure -> Implement login system -> Add data visualization -> Integrate external API\"\n        elif \"implementation\" in prompt:\n            return json.dumps({\"response\": \"def main():\\n    print('Hello, world!')\", \"file_path\": \"src/app.py\"})\n        else:\n            return \"FINISHED WITH SCRIPT\"\n\ndef ensure_directory_exists(path):\n    os.makedirs(path, exist_ok=True)\n\ndef write_or_update_file(file_path, content):\n    if os.path.exists(file_path):\n        base, extension = os.path.splitext(file_path)\n        version = 1\n        new_file_path = f\"{base}_updated{version}{extension}\"\n        while os.path.exists(new_file_path):\n            version += 1\n            new_file_path = f\"{base}_updated{version}{extension}\"\n        file_path = new_file_path\n    with open(file_path, 'w') as file:\n        file.write(content)\n\ndef main():\n    dotenv_path = os.path.join(os.path.dirname(__file__), 'config', '.env')\n    openAI = OpenAIKeyLoader(dotenv_path)\n    nlp_client = NLPClient()\n    memory_manager = ModuleMemory()\n    project_folder_creator = ProjectFolderCreator(memory_manager)\n    project_folder_creator.create_project_directory()\n    nlp_processor = NLPProcessor(memory_manager)\n    generator = PromptGenerator()\n    prompt_context = []\n\n    project_name = input(\"Enter project name: \")\n    project_description = input(\"Enter project description: \")\n\n    prompt_context.append(project_name)\n    prompt_context.append(project_description)\n    role = \"You are a great App Developer\"\n    messages = []\n    messages.append({\"role\": \"system\", \"content\": role})\n\n    # Generate prompt and get feature list\n    feature_list_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the given project title and description, provide a comprehensive feature and functionality list.\",\n        context_items={\"project_name\": project_name, \"project_description\": project_description},\n        response_format=\"json\",\n        response_structure={\"features\" : [{ \"name\": str, \"description\": str}]},\n        instructions=[\"Prepare a list of features and functionalities for the project.\",\n                      \"Include all the necessary features for a complete application.\"],\n    )\n    generator.set_context(feature_list_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, feature_list_context)\n    parsed_response = parse_response(response)\n    features = parsed_response\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Features:\", features)\n\n    # Generate prompt and get file and folder structure\n    structure_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the feature list, provide the file and folder structure for the project.\",\n        # context_items={\"feature_list\": features},\n        response_format=\"json\",\n        response_structure={ \"files\" : [ { \"name\": str, \"file_path\": str, \"description\": str } ], \"folders\" : [ { \"name\": str, \"description\": str } ] },\n        instructions=[\"Prepare a file and folder structure for the project.\",\n                      \"Include all the necessary files and folders for a complete application.\"],\n    )\n    generator.set_context(structure_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, structure_context)\n    parsed_response = parse_response(response)\n    structure = parsed_response\n    file_list = structure[\"files\"]\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Structure:\", structure)\n\n\n    # Generate Implementation Plan\n    plan_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the file and folder structure, provide a plan for implementation.\",\n        # context_items={\"structure\": structure},\n        response_format=\"json\",\n        response_structure={\"plan\": str},\n        instructions=[\"Prepare a plan for implementing the project.\",\n                      \"Include all the necessary steps for a complete application.\"],\n    )\n    generator.set_context(plan_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, plan_context)\n    parsed_response = parse_response(response)\n    plan = parsed_response\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Plan:\", plan)\n\n\n    # Iterate through the files and implement the project\n    for file in file_list:\n        file_name = file[\"name\"]\n        file_description = file[\"description\"]\n        file_path = file[\"file_path\"]\n\n        # Generate prompt and get feature list for the file as well as file_path in array format\n        feature_list_context = PromptContext(\n            role=\"You are a great App Developer\",\n            simple_prompt=\"Based on the given project title and description, provide a comprehensive feature and functionality list.\",\n            context_items={\"file_name\": file_name, \"file_description\": file_description, \"file_path\": file_path},\n            response_format=\"json\",\n            response_structure={\"features\" : [{ \"name\": str, \"description\": str}], \"file_path_array\": [str]},\n            instructions=[\"Prepare a list of features and functionalities for the project.\",\n                          \"Include all the necessary features for a complete application.\"],\n        )\n        generator.set_context(feature_list_context)\n        prompt = generator.generate_prompt()\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        response = nlp_processor.process(messages, feature_list_context)\n        parsed_response = parse_response(response)\n        features = parsed_response\n        file[\"features\"] = features\n        file[\"file_path_array\"] = parsed_response[\"file_path_array\"]\n        messages.append({\"role\": \"assistant\", \"content\": response})\n        print(\"Features:\", features)\n\n\n        # Generate prompt and get code implementation\n        implementation_context = PromptContext(\n            role=\"You are a great App Developer\",\n            simple_prompt=\"Lets start implementing the project step by step and generate the code for an initial file, then improve file by file the codebase.\",\n            context_items={\"file_name\": file_name, \"file_description\": file_description, \"file_path\": file_path, \"features\": features},\n            response_format=\"json\",\n            response_structure={\"file_path\": str, \"code\": str, \"file_instruction\": str},\n            instructions=[\"Generate the code for the initial file.\",\n                          \"Generate a comprehensive and well coded implementation code for the current file.\",\n                          \"Also generate brief instruction on how to use the file and what it does.\",\n                          \"Provide the response in the given response format and structure.\"],\n        )\n        generator.set_context(implementation_context)\n        prompt = generator.generate_prompt()\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        response = nlp_processor.process(messages, implementation_context)\n        parsed_response = parse_response(response)\n        coded_file = parsed_response\n        file[\"code\"] = coded_file\n        file[\"file_instruction\"] = parsed_response[\"file_instruction\"]\n        messages.append({\"role\": \"assistant\", \"content\": response})\n        print(\"Coded File:\", coded_file)\n\n        # Check and create folder structure\n        # ensure_directory_exists(os.path.dirname(file_path))\n        # write_or_update_file(file_path, implementation[\"code\"])\n        # print(\"File created at:\", file_path)\n  \n\n    memory_manager.save_to_file(\"memory.json\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "test2.py": "import os\n\nclass NLPClient:\n    def __init__(self, gpt_model=\"GPT_MODEL\"):\n        self.gpt_model = gpt_model\n        # This client is a placeholder. In a real scenario, this would interface with OpenAI's API.\n    \n    def process(self, messages, role, use_json_completion=False):\n        # This is a mockup function. You should replace this with actual calls to the NLP API.\n        # For demonstration, it returns predefined responses based on the role.\n        if role == \"request_features\":\n            return [\"Login system\", \"Data visualization\", \"API integration\"]\n        elif role == \"request_structure\":\n            return {\n                \"folders\": [\"src\", \"docs\", \"tests\"],\n                \"files\": [\"src/app.py\", \"src/utils.py\", \"README.md\"]\n            }\n        elif role == \"request_implementation_plan\":\n            return \"1. Setup project structure. 2. Implement login system. 3. Add data visualization. 4. Integrate external API.\"\n        elif role == \"request_implementation\":\n            return {\"response\": \"def main():\\n    print('Hello, world!')\", \"file_path\": \"src/app.py\"}\n        elif role == \"finish_script\":\n            return \"FINISHED WITH SCRIPT\"\n        else:\n            return \"Unknown role\"\n\ndef ensure_directory_exists(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef write_or_update_file(file_path, content):\n    if os.path.exists(file_path):\n        base, extension = os.path.splitext(file_path)\n        version = 1\n        new_file_path = f\"{base}_updated{version}{extension}\"\n        while os.path.exists(new_file_path):\n            version += 1\n            new_file_path = f\"{base}_updated{version}{extension}\"\n        file_path = new_file_path\n    \n    with open(file_path, 'w') as file:\n        file.write(content)\n\ndef main():\n    nlp_client = NLPClient()\n    memory_string = \"\"\n    prompt_string = {\"instructions\": \"\", \"context\": \"\", \"tech_stack\": \"\"}\n    \n    # Setup process\n    project_name = \"MyProject\"\n    project_description = \"A project to demonstrate NLP-driven development.\"\n    \n    # Request feature list\n    features = nlp_client.process([project_name, project_description], \"request_features\")\n    memory_string += f\"Features: {features}\\n\"\n    \n    # Request file and folder structure\n    structure = nlp_client.process(memory_string, \"request_structure\")\n    memory_string += f\"Structure: {structure}\\n\"\n    \n    # Request plan for implementation\n    plan = nlp_client.process(memory_string, \"request_implementation_plan\")\n    memory_string += f\"Plan: {plan}\\n\"\n    \n    # Add memory_string to prompt_string\n    prompt_string[\"context\"] = memory_string\n    \n    # Implement the first file\n    implementation_response = nlp_client.process(prompt_string, \"request_implementation\")\n    prompt_string[\"instructions\"] = implementation_response[\"response\"]\n    file_path = implementation_response[\"file_path\"]\n    \n    # Check and handle file and folder creation\n    folder_path = os.path.dirname(file_path)\n    ensure_directory_exists(folder_path)\n    write_or_update_file(file_path, prompt_string[\"instructions\"])\n    \n    while \"FINISHED WITH SCRIPT\" not in prompt_string[\"instructions\"]:\n        implementation_response = nlp_client.process(prompt_string, \"request_implementation\")\n        prompt_string[\"instructions\"] = implementation_response[\"response\"]\n        file_path = implementation_response[\"file_path\"]\n        \n        folder_path = os.path.dirname(file_path)\n        ensure_directory_exists(folder_path)\n        write_or_update_file(file_path, prompt_string[\"instructions\"])\n\nif __name__ == \"__main__\":\n    main()\n",
    "test BACKUP.py": "import os\nimport json\nfrom maldinio_ai import NLPClient, PromptContext, PromptGenerator, OpenAIKeyLoader, NLPProcessor, ModuleMemory\nfrom ProjectFolderCreator import ProjectFolderCreator\nfrom MemoryManager import MemoryManager\n\ndef parse_response(response):\n    try:\n        # Try parsing the response as is\n        return json.loads(response)\n    except json.decoder.JSONDecodeError as e:\n        # If a JSONDecodeError is encountered, try fixing the quotes\n        try:\n            corrected_response = response.replace(\"'\", '\"')\n            return json.loads(corrected_response)\n        except Exception as e:\n            # Log the error, raise an exception, or handle it as needed\n            print(f\"Failed to parse the response even after quote correction: {e}\")\n            raise\n\n# Simulated NLP client using the PromptContext and PromptGenerator\nclass MockNLPClient:\n    def process(self, prompt):\n        print(f\"Sending prompt to NLP model: {prompt}\")\n        # This is where you'd send the prompt to the actual NLP model. For now, it returns mocked responses.\n        if \"feature list\" in prompt:\n            return json.dumps([\"Login system\", \"Data visualization\", \"API integration\"])\n        elif \"file and folder structure\" in prompt:\n            return json.dumps({\n                \"folders\": [\"src\", \"docs\", \"tests\"],\n                \"files\": [\"src/app.py\", \"src/utils.py\", \"README.md\"]\n            })\n        elif \"implementation plan\" in prompt:\n            return \"Setup project structure -> Implement login system -> Add data visualization -> Integrate external API\"\n        elif \"implementation\" in prompt:\n            return json.dumps({\"response\": \"def main():\\n    print('Hello, world!')\", \"file_path\": \"src/app.py\"})\n        else:\n            return \"FINISHED WITH SCRIPT\"\n\ndef ensure_directory_exists(path):\n    os.makedirs(path, exist_ok=True)\n\ndef write_or_update_file(file_path, content):\n    if os.path.exists(file_path):\n        base, extension = os.path.splitext(file_path)\n        version = 1\n        new_file_path = f\"{base}_updated{version}{extension}\"\n        while os.path.exists(new_file_path):\n            version += 1\n            new_file_path = f\"{base}_updated{version}{extension}\"\n        file_path = new_file_path\n    with open(file_path, 'w') as file:\n        file.write(content)\n\ndef main():\n    dotenv_path = os.path.join(os.path.dirname(__file__), 'config', '.env')\n    openAI = OpenAIKeyLoader(dotenv_path)\n    nlp_client = NLPClient()\n    memory_manager = ModuleMemory()\n    project_folder_creator = ProjectFolderCreator(memory_manager)\n    project_folder_creator.create_project_directory()\n    nlp_processor = NLPProcessor(memory_manager)\n    generator = PromptGenerator()\n    prompt_context = []\n\n    project_name = input(\"Enter project name: \")\n    project_description = input(\"Enter project description: \")\n\n    prompt_context.append(project_name)\n    prompt_context.append(project_description)\n    role = \"You are a great App Developer\"\n    messages = []\n    messages.append({\"role\": \"system\", \"content\": role})\n\n    # Generate prompt and get feature list\n    feature_list_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the given project title and description, provide a comprehensive feature and functionality list.\",\n        context_items={\"project_name\": project_name, \"project_description\": project_description},\n        response_format=\"json\",\n        response_structure={\"features\" : [{ \"name\": str, \"description\": str}]},\n        instructions=[\"Prepare a list of features and functionalities for the project.\",\n                      \"Include all the necessary features for a complete application.\"],\n    )\n    generator.set_context(feature_list_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, feature_list_context)\n    parsed_response = parse_response(response)\n    features = parsed_response\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Features:\", features)\n\n    # Generate prompt and get file and folder structure\n    structure_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the feature list, provide the file and folder structure for the project.\",\n        # context_items={\"feature_list\": features},\n        response_format=\"json\",\n        response_structure={ \"files\" : [ { \"name\": str, \"file_path\": str, \"description\": str } ], \"folders\" : [ { \"name\": str, \"description\": str } ] },\n        instructions=[\"Prepare a file and folder structure for the project.\",\n                      \"Include all the necessary files and folders for a complete application.\"],\n    )\n    generator.set_context(structure_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, structure_context)\n    parsed_response = parse_response(response)\n    structure = parsed_response\n    file_list = structure[\"files\"]\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Structure:\", structure)\n\n\n    # Generate Implementation Plan\n    plan_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the file and folder structure, provide a plan for implementation.\",\n        # context_items={\"structure\": structure},\n        response_format=\"json\",\n        response_structure={\"plan\": str},\n        instructions=[\"Prepare a plan for implementing the project.\",\n                      \"Include all the necessary steps for a complete application.\"],\n    )\n    generator.set_context(plan_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, plan_context)\n    parsed_response = parse_response(response)\n    plan = parsed_response\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Plan:\", plan)\n\n\n    # Iterate through the files and implement the project\n    for file in file_list:\n        file_name = file[\"name\"]\n        file_description = file[\"description\"]\n        file_path = file[\"file_path\"]\n\n        # Generate prompt and get feature list for the file as well as file_path in array format\n        feature_list_context = PromptContext(\n            role=\"You are a great App Developer\",\n            simple_prompt=\"Based on the given project title and description, provide a comprehensive feature and functionality list.\",\n            context_items={\"file_name\": file_name, \"file_description\": file_description, \"file_path\": file_path},\n            response_format=\"json\",\n            response_structure={\"features\" : [{ \"name\": str, \"description\": str}], \"file_path_array\": [str]},\n            instructions=[\"Prepare a list of features and functionalities for the project.\",\n                          \"Include all the necessary features for a complete application.\"],\n        )\n        generator.set_context(feature_list_context)\n        prompt = generator.generate_prompt()\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        response = nlp_processor.process(messages, feature_list_context)\n        parsed_response = parse_response(response)\n        features = parsed_response\n        file[\"features\"] = features\n        file[\"file_path_array\"] = parsed_response[\"file_path_array\"]\n        messages.append({\"role\": \"assistant\", \"content\": response})\n        print(\"Features:\", features)\n\n\n        # Generate prompt and get code implementation\n        implementation_context = PromptContext(\n            role=\"You are a great App Developer\",\n            simple_prompt=\"Lets start implementing the project step by step and generate the code for an initial file, then improve file by file the codebase.\",\n            context_items={\"file_name\": file_name, \"file_description\": file_description, \"file_path\": file_path, \"features\": features},\n            response_format=\"json\",\n            response_structure={\"file_path\": str, \"code\": str, \"file_instruction\": str},\n            instructions=[\"Generate the code for the initial file.\",\n                          \"Generate a comprehensive and well coded implementation code for the current file.\",\n                          \"Also generate brief instruction on how to use the file and what it does.\",\n                          \"Provide the response in the given response format and structure.\"],\n        )\n        generator.set_context(implementation_context)\n        prompt = generator.generate_prompt()\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        response = nlp_processor.process(messages, implementation_context)\n        parsed_response = parse_response(response)\n        coded_file = parsed_response\n        file[\"code\"] = coded_file\n        file[\"file_instruction\"] = parsed_response[\"file_instruction\"]\n        messages.append({\"role\": \"assistant\", \"content\": response})\n        print(\"Implementation:\", implementation)\n\n        # Check and create folder structure\n        # ensure_directory_exists(os.path.dirname(file_path))\n        # write_or_update_file(file_path, implementation[\"code\"])\n        # print(\"File created at:\", file_path)\n   \n\n\n\n    # Generate prompt and get implementation\n    initial_implementation_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Lets start implementing the project step by step and generate the code for an initial file, then improve file by file the codebase.\",\n        # context_items={\"plan\": plan},\n        response_format=\"json\",\n        response_structure={\"file_path\": str, \"code\": str},\n        instructions=[\"Generate the code for the initial file.\",\n                      \"Please generate a comprehensive and well coded implementation code for an initial file.\"],\n                      # \"Provide the response in the given response format and structure.\"\n    )\n    generator.set_context(initial_implementation_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, initial_implementation_context)\n    # parsed_response = parse_response(response)\n    # implementation = json.loads(response)\n    implementation = response\n    # file_path = implementation[\"file_path\"]\n    # file_content = implementation[\"code\"]\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    # print(\"Implementation:\", file_content)\n    print(\"Implementation:\", implementation)\n\n\n    # Check and create folder structure\n    # ensure_directory_exists(os.path.dirname(file_path))\n    # write_or_update_file(file_path, file_content)\n    # print(\"File created at:\", file_path)\n\n    # Loop for file implementation\n    while \"FINISHED WITH SCRIPT\" not in implementation:\n        implementation_context = PromptContext(\n            role=\"You are a great App Developer\",\n            simple_prompt=\"Great! Lets continue with the next file. Please generate a comprehensive and well coded implementation code for the next file.\",\n            # response_format=\"json\",\n            # response_structure={\"file_path\": str, \"code\": str},\n            instructions=[\"Generate the code for the next file.\", \n                          \"Please generate a comprehensive and well coded implementation code for the next file.\",\n                          \"We will develop the app file by file.\",\n                          \"Once you finished all files and did several iterations to improve them and you believe the project is finished, please respond simply with [FINISHED WITH SCRIPT]\" ] #, \"Provide the response in the given response format and structure.\"],\n        )\n        generator.set_context(implementation_context)\n        prompt = generator.generate_prompt()\n        print()\n        print (\"prompt:\", prompt)\n        print()\n        print (\"messages:\", messages)\n        print()\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        response = nlp_processor.process(messages, implementation_context)\n        # parsed_response = parse_response(response)\n        # implementation = json.loads(response)\n        implementation = response\n        # file_path = implementation[\"file_path\"]\n        # file_content = implementation[\"code\"]\n        messages.append({\"role\": \"assistant\", \"content\": response})\n        # print(\"Implementation:\", file_content)\n        print(\"Implementation:\", implementation)\n\n        # Check and create folder structure\n        # ensure_directory_exists(os.path.dirname(file_path))\n        # write_or_update_file(file_path, file_content)\n        # print(\"File created at:\", file_path)\n\n    memory_manager.save_to_file(\"memory.json\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "test_json.py": "import os\nimport json\nfrom maldinio_ai import NLPClient, PromptContext, PromptGenerator, OpenAIKeyLoader, NLPProcessor, ModuleMemory\nfrom ProjectFolderCreator import ProjectFolderCreator\nfrom MemoryManager import MemoryManager\n\n# Simulated NLP client using the PromptContext and PromptGenerator\nclass MockNLPClient:\n    def process(self, prompt):\n        print(f\"Sending prompt to NLP model: {prompt}\")\n        # This is where you'd send the prompt to the actual NLP model. For now, it returns mocked responses.\n        if \"feature list\" in prompt:\n            return json.dumps([\"Login system\", \"Data visualization\", \"API integration\"])\n        elif \"file and folder structure\" in prompt:\n            return json.dumps({\n                \"folders\": [\"src\", \"docs\", \"tests\"],\n                \"files\": [\"src/app.py\", \"src/utils.py\", \"README.md\"]\n            })\n        elif \"implementation plan\" in prompt:\n            return \"Setup project structure -> Implement login system -> Add data visualization -> Integrate external API\"\n        elif \"implementation\" in prompt:\n            return json.dumps({\"response\": \"def main():\\n    print('Hello, world!')\", \"file_path\": \"src/app.py\"})\n        else:\n            return \"FINISHED WITH SCRIPT\"\n\ndef ensure_directory_exists(path):\n    os.makedirs(path, exist_ok=True)\n\ndef write_or_update_file(file_path, content):\n    if os.path.exists(file_path):\n        base, extension = os.path.splitext(file_path)\n        version = 1\n        new_file_path = f\"{base}_updated{version}{extension}\"\n        while os.path.exists(new_file_path):\n            version += 1\n            new_file_path = f\"{base}_updated{version}{extension}\"\n        file_path = new_file_path\n    with open(file_path, 'w') as file:\n        file.write(content)\n\ndef main():\n    dotenv_path = os.path.join(os.path.dirname(__file__), 'config', '.env')\n    openAI = OpenAIKeyLoader(dotenv_path)\n    nlp_client = NLPClient()\n    memory_manager = ModuleMemory()\n    project_folder_creator = ProjectFolderCreator(memory_manager)\n    project_folder_creator.create_project_directory()\n    nlp_processor = NLPProcessor(memory_manager)\n    generator = PromptGenerator()\n    prompt_context = []\n\n    project_name = input(\"Enter project name: \")\n    project_description = input(\"Enter project description: \")\n\n    prompt_context.append(project_name)\n    prompt_context.append(project_description)\n    role = \"You are a great App Developer\"\n    messages = []\n    messages.append({\"role\": \"system\", \"content\": role})\n\n    # Generate prompt and get feature list\n    feature_list_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the given project title and description, provide a comprehensive feature and functionality list.\",\n        context_items={\"project_name\": project_name, \"project_description\": project_description},\n        instructions=[\"Prepare a list of features and functionalities for the project.\",\n                      \"Include all the necessary features for a complete application.\"],\n    )\n    generator.set_context(feature_list_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, feature_list_context)\n    features = response\n    messages.append({\"role\": \"assistant\", \"content\": features})\n    print(\"Features:\", features)\n\n    # Generate prompt and get file and folder structure\n    structure_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the feature list, provide the file and folder structure for the project.\",\n        # context_items={\"feature_list\": features},\n        instructions=[\"Prepare a file and folder structure for the project.\",\n                      \"Include all the necessary files and folders for a complete application.\"],\n    )\n    generator.set_context(structure_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, structure_context)\n    structure = response\n    messages.append({\"role\": \"assistant\", \"content\": structure})\n    print(\"Structure:\", structure)\n\n\n    # Generate Implementation Plan\n    plan_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Based on the file and folder structure, provide a plan for implementation.\",\n        # context_items={\"structure\": structure},\n        instructions=[\"Prepare a plan for implementing the project.\",\n                      \"Include all the necessary steps for a complete application.\"],\n    )\n    generator.set_context(plan_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, plan_context)\n    plan = response\n    messages.append({\"role\": \"assistant\", \"content\": plan})\n    print(\"Plan:\", plan)\n\n\n    def parse_response(response):\n        try:\n            # Try parsing the response as is\n            return json.loads(response)\n        except json.decoder.JSONDecodeError as e:\n            # If a JSONDecodeError is encountered, try fixing the quotes\n            try:\n                corrected_response = response.replace(\"'\", '\"')\n                return json.loads(corrected_response)\n            except Exception as e:\n                # Log the error, raise an exception, or handle it as needed\n                print(f\"Failed to parse the response even after quote correction: {e}\")\n                raise\n\n\n    # Generate prompt and get implementation\n    initial_implementation_context = PromptContext(\n        role=\"You are a great App Developer\",\n        simple_prompt=\"Lets start implementing the project. Please generate a comprehensive and well coded implementation code for an initial file.\",\n        # context_items={\"plan\": plan},\n        response_format=\"json\",\n        response_structure={\"file_path\": str, \"code\": str},\n        instructions=[\"Generate the code for the initial file.\",\n                      \"Follow the plan for implementation.\",\n                      \"Provide the response in the given response format and structure.\"],\n    )\n    generator.set_context(initial_implementation_context)\n    prompt = generator.generate_prompt()\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    response = nlp_processor.process(messages, initial_implementation_context)\n    parsed_response = parse_response(response)\n    implementation = json.loads(response)\n    file_path = implementation[\"file_path\"]\n    file_content = implementation[\"code\"]\n    messages.append({\"role\": \"assistant\", \"content\": response})\n    print(\"Implementation:\", file_content)\n\n\n    # Check and create folder structure\n    # ensure_directory_exists(os.path.dirname(file_path))\n    # write_or_update_file(file_path, file_content)\n    # print(\"File created at:\", file_path)\n\n    # Loop for file implementation\n    while \"FINISHED WITH SCRIPT\" not in file_content:\n        implementation_context = PromptContext(\n            role=\"You are a great App Developer\",\n            simple_prompt=\"Great! Lets continue with the next file. Please generate a comprehensive and well coded implementation code for the next file.\",\n            response_format=\"json\",\n            response_structure={\"file_path\": str, \"code\": str},\n            instructions=[\"Generate the code for the next file.\", \"Provide the response in the given response format and structure.\"],\n        )\n        generator.set_context(implementation_context)\n        prompt = generator.generate_prompt()\n        print()\n        print (\"prompt:\", prompt)\n        print()\n        print (\"messages:\", messages)\n        print()\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        response = nlp_processor.process(messages, implementation_context)\n        parsed_response = parse_response(response)\n        implementation = parsed_response\n        file_path = implementation[\"file_path\"]\n        file_content = implementation[\"code\"]\n        messages.append({\"role\": \"assistant\", \"content\": response})\n        print(\"Implementation:\", file_content)\n\n        # Check and create folder structure\n        # ensure_directory_exists(os.path.dirname(file_path))\n        # write_or_update_file(file_path, file_content)\n        # print(\"File created at:\", file_path)\n\n    memory_manager.save_to_file(\"memory.json\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "simple_generator.py": "import os\n\n# Function to interact with NLP model (mockup, replace with actual API calls)\ndef interact_with_nlp(prompt):\n    # This function should be replaced with actual API calls to an NLP service\n    # For demonstration, we'll return a placeholder response\n    return {\"response\": \"Placeholder response\", \"file_path\": \"placeholder/path/to/file.py\"}\n\n# Function to check and create folder structure\ndef ensure_folder_structure(path):\n    folder_path = os.path.dirname(path)\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n# Function to handle file creation and updates\ndef create_or_update_file(file_path, content):\n    if os.path.exists(file_path):\n        base, extension = os.path.splitext(file_path)\n        i = 1\n        new_file_path = f\"{base}_updated{i}{extension}\"\n        while os.path.exists(new_file_path):\n            i += 1\n            new_file_path = f\"{base}_updated{i}{extension}\"\n        file_path = new_file_path\n\n    with open(file_path, 'w') as file:\n        file.write(content)\n    return file_path\n\n# Main process\ndef main():\n    memory_string = \"\"\n\n    # Step 1: Request feature list\n    project_name_and_description = \"Project Name: Example Project, Description: This is an example project description.\"\n    response = interact_with_nlp(project_name_and_description)\n    memory_string += \"\\n\" + response[\"response\"]\n\n    # Step 2: Request file and folder structure\n    response = interact_with_nlp(memory_string)\n    memory_string += \"\\n\" + response[\"response\"]\n\n    # Step 3: Request plan for implementation\n    response = interact_with_nlp(memory_string)\n    memory_string += \"\\n\" + response[\"response\"]\n\n    # Initialize prompt string with attributes\n    prompt_string = f\"Instructions: Implement the first file.\\nContext: {memory_string}\\nTech Stack: Python\"\n\n    # Begin loop for file implementation\n    while True:\n        response = interact_with_nlp(prompt_string)\n        file_path = response[\"file_path\"]\n        file_content = response[\"response\"]\n\n        if \"FINISHED WITH SCRIPT\" in file_content:\n            break\n\n        # Check and create folder structure\n        ensure_folder_structure(file_path)\n\n        # Create or update the file\n        actual_file_path = create_or_update_file(file_path, file_content)\n\n        # Update prompt_string for the next iteration\n        prompt_string += f\"\\nFile Path: {actual_file_path}\\nResponse: {file_content}\"\n\nif __name__ == \"__main__\":\n    main()\n"
}